{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hi everyone!\n<br>\nI'm Aditya, this notebook will present analysis related data from <url>https://www.kaggle.com/datasets/mfaisalqureshi/spam-email</url>. For detail explanation, see <url>https://medium.com/@adityaadamf</url>.\n<br>\nThank you!","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Install and import library","metadata":{}},{"cell_type":"code","source":"!pip install -q polars pyarrow plotly kaleido imbalanced-learn","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:45:15.783954Z","iopub.execute_input":"2023-09-18T05:45:15.784384Z","iopub.status.idle":"2023-09-18T05:45:42.617355Z","shell.execute_reply.started":"2023-09-18T05:45:15.784351Z","shell.execute_reply":"2023-09-18T05:45:42.616195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import polars as pl\nimport pandas as pd\nimport numpy as np\nimport re, random, os, warnings\nwarnings.filterwarnings('ignore')\nimport plotly.express as px\nimport plotly.io as pio\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom sklearn.preprocessing import LabelEncoder\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport tensorflow as tf\nrandom.seed(0)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:45:42.619357Z","iopub.execute_input":"2023-09-18T05:45:42.619646Z","iopub.status.idle":"2023-09-18T05:46:24.717677Z","shell.execute_reply.started":"2023-09-18T05:45:42.619618Z","shell.execute_reply":"2023-09-18T05:46:24.716578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl.Config(fmt_str_lengths=1500)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:24.718896Z","iopub.execute_input":"2023-09-18T05:46:24.719384Z","iopub.status.idle":"2023-09-18T05:46:24.729079Z","shell.execute_reply.started":"2023-09-18T05:46:24.719355Z","shell.execute_reply":"2023-09-18T05:46:24.728097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"df = pl.read_csv('/kaggle/input/spam-email/spam.csv')","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:24.730128Z","iopub.execute_input":"2023-09-18T05:46:24.730396Z","iopub.status.idle":"2023-09-18T05:46:24.771249Z","shell.execute_reply.started":"2023-09-18T05:46:24.730371Z","shell.execute_reply":"2023-09-18T05:46:24.770240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('dataset has {} rows and {} columns'.format(df.shape[0], df.shape[1]))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:24.773862Z","iopub.execute_input":"2023-09-18T05:46:24.774185Z","iopub.status.idle":"2023-09-18T05:46:24.779813Z","shell.execute_reply.started":"2023-09-18T05:46:24.774157Z","shell.execute_reply":"2023-09-18T05:46:24.778824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:24.780936Z","iopub.execute_input":"2023-09-18T05:46:24.781242Z","iopub.status.idle":"2023-09-18T05:46:24.792493Z","shell.execute_reply.started":"2023-09-18T05:46:24.781214Z","shell.execute_reply":"2023-09-18T05:46:24.791546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization","metadata":{}},{"cell_type":"markdown","source":"Display visualization number of data from each spam label","metadata":{}},{"cell_type":"code","source":"viz_spam_label = df.group_by('Category').count()\npx.pie(viz_spam_label, title='(1) Proportion of Spam Label',\n       values='count', names='Category').show(renderer='svg')","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:24.793702Z","iopub.execute_input":"2023-09-18T05:46:24.794103Z","iopub.status.idle":"2023-09-18T05:46:27.292345Z","shell.execute_reply.started":"2023-09-18T05:46:24.794074Z","shell.execute_reply":"2023-09-18T05:46:27.291015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"See, the result of spam label visualization above. `76.1%` (4360) not spam and `23.9%` (1368) spam, the result indicate imbalance data.","metadata":{}},{"cell_type":"markdown","source":"# Preprocessing\nStep in this processing, I will:\n1. Remove symbol `(such as !@#$%&*...etc)`\n<br><br>\n<i>for this notebook, I don't use spelling correction and stemming, because for time efficiency</i>","metadata":{}},{"cell_type":"code","source":"def preprocess(texts):\n    # remove symbol\n    texts = re.sub(r'[\\W_]+',' ',texts)\n    return texts","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:27.294113Z","iopub.execute_input":"2023-09-18T05:46:27.294834Z","iopub.status.idle":"2023-09-18T05:46:27.300563Z","shell.execute_reply.started":"2023-09-18T05:46:27.294797Z","shell.execute_reply":"2023-09-18T05:46:27.299526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.with_columns(pl.col('Message').map_elements(lambda x: preprocess(x)))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:27.301716Z","iopub.execute_input":"2023-09-18T05:46:27.302040Z","iopub.status.idle":"2023-09-18T05:46:27.403296Z","shell.execute_reply.started":"2023-09-18T05:46:27.302011Z","shell.execute_reply":"2023-09-18T05:46:27.402012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:27.404682Z","iopub.execute_input":"2023-09-18T05:46:27.405024Z","iopub.status.idle":"2023-09-18T05:46:27.412975Z","shell.execute_reply.started":"2023-09-18T05:46:27.404994Z","shell.execute_reply":"2023-09-18T05:46:27.412042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformation\nIn transformation step, I will create vocab and train from existing text data using tensorflow `TextVectorization` and output_mode is `tf_idf`. Then save the transformation model in format `tf`","metadata":{}},{"cell_type":"code","source":"def transformers(X: list, is_train: bool=True, \n                 paths: dict={'model':'model/transformation', \n                              'vocab':'model/numpy'}, \n                 output: str='tf_idf', save_format: str='tf'):\n    if is_train:\n        # Create vocabulary data\n        vocab_data = tf.data.Dataset.from_tensor_slices( \n            list( np.sort( np.unique(' '.join(X).split()) ) ) \n        )\n\n        # TextVectorization\n        tfidf_layer = tf.keras.layers.TextVectorization(\n            standardize = 'lower_and_strip_punctuation',\n            split = 'whitespace',\n            max_tokens = len(vocab_data),\n            output_mode = output\n        )\n        tfidf_layer.adapt(vocab_data.batch(64))\n\n        # Save the vocabulary in numpy save compressed\n        vocab_list = tfidf_layer.get_vocabulary()\n        if not os.path.exists(paths['vocab']):\n            os.makedirs(paths['vocab'])\n        np.savez_compressed(paths['vocab']+'/vocab.npz', vocab=vocab_list)\n        \n        # Create transformation model\n        model = tf.keras.models.Sequential()\n        model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n        model.add(tfidf_layer)\n        \n        # Save transformer model\n        model.save(paths['model'])\n        \n        # Predict\n        X_pred = model.predict(X, verbose=0)\n    else:\n        vocab_list = np.load(paths['vocab']+'/vocab.npz')['vocab']\n        model = tf.keras.models.load_model(paths['model'], compile=False)\n        \n        X_pred = model.predict(X, verbose=0)\n        \n    return X_pred, vocab_list","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:27.414184Z","iopub.execute_input":"2023-09-18T05:46:27.414483Z","iopub.status.idle":"2023-09-18T05:46:27.428834Z","shell.execute_reply.started":"2023-09-18T05:46:27.414456Z","shell.execute_reply":"2023-09-18T05:46:27.427809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, vocab_list = transformers(df['Message'].to_list())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-09-18T05:46:27.430052Z","iopub.execute_input":"2023-09-18T05:46:27.430350Z","iopub.status.idle":"2023-09-18T05:46:34.428500Z","shell.execute_reply.started":"2023-09-18T05:46:27.430324Z","shell.execute_reply":"2023-09-18T05:46:34.427292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next for variable y, I will convert to numeric using LabelEncoder","metadata":{}},{"cell_type":"code","source":"def label_encoder(y: list, name: str, is_train: bool=True, paths: dict={'label':'model/numpy'}):\n    lists = np.sort(np.unique(y)) if is_train else np.load(paths['label']+'/list_'+name+'.npy')\n    if is_train:\n        np.save(paths['label']+'/list_'+name+'.npy', lists)\n\n    le = LabelEncoder()\n    le_encode = le.fit(lists)\n    le_encode = le_encode.transform(y)\n    le_encode = tf.keras.utils.to_categorical(le_encode)\n    \n    return le_encode","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:34.429968Z","iopub.execute_input":"2023-09-18T05:46:34.430310Z","iopub.status.idle":"2023-09-18T05:46:34.438543Z","shell.execute_reply.started":"2023-09-18T05:46:34.430280Z","shell.execute_reply":"2023-09-18T05:46:34.437579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = label_encoder(df['Category'], df['Category'].name)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:34.442831Z","iopub.execute_input":"2023-09-18T05:46:34.443186Z","iopub.status.idle":"2023-09-18T05:46:34.461239Z","shell.execute_reply.started":"2023-09-18T05:46:34.443157Z","shell.execute_reply":"2023-09-18T05:46:34.460203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split data\nBefore I go to next step, <b>5572</b> data will be split into three:\n<br>\n`Use 80:20 proportion theory`<sup>[1]</sup>\n- `80%` <b>(4457)</b> Train: <i>from 80% data, will split again for model evaluate, `80%` <b>(3565)</b> for Train and `20%` <b>(892)</b> for Validation</i>\n- `20%` <b>(1115)</b> Test.\n<br>\nWhy did I do it here?\n<br>\n- For short answer, because for the better experiments :D\n<br>\n- For detail answer, because `Train data` set for learning model, `Validation data` set to provide an unbiased evaluation of a model fitted, and `Test data` set to provide an unbiased evaluation of a final model <sup>[2]</sup>","metadata":{}},{"cell_type":"code","source":"# Split into Train and Test\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size = 0.2, train_size = 0.8, \n                                                    stratify = y, random_state = 42)\n\nprint('size of train: {}, size of test: {}'.format(X_train.shape, X_test.shape))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:34.462485Z","iopub.execute_input":"2023-09-18T05:46:34.462816Z","iopub.status.idle":"2023-09-18T05:46:34.575125Z","shell.execute_reply.started":"2023-09-18T05:46:34.462786Z","shell.execute_reply":"2023-09-18T05:46:34.573808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From Train, split again into Train and Valid\nX_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, \n                                                      test_size = 0.2, train_size = 0.8, \n                                                      stratify = y_train, random_state = 42)\n\nprint('size of train: {}, size of valid: {}'.format(X_train.shape, X_valid.shape))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:34.576515Z","iopub.execute_input":"2023-09-18T05:46:34.576919Z","iopub.status.idle":"2023-09-18T05:46:34.666192Z","shell.execute_reply.started":"2023-09-18T05:46:34.576876Z","shell.execute_reply":"2023-09-18T05:46:34.664881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resampling\nWhy I add resampling step? Because see the visualization output (img.1), the result from each spam label is not equal. So for minority class, need to be resampling until it's equal to majority class. The method I use is ROS (Random Over Sampling): SMOTE<sup>[3]</sup>","metadata":{}},{"cell_type":"code","source":"res = SMOTE(random_state=42)\nX_res, y_res = res.fit_resample(X_train, y_train.argmax(1))\nprint('Resampled dataset shape %s' % Counter(y_res))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:34.667560Z","iopub.execute_input":"2023-09-18T05:46:34.667935Z","iopub.status.idle":"2023-09-18T05:46:36.788858Z","shell.execute_reply.started":"2023-09-18T05:46:34.667902Z","shell.execute_reply":"2023-09-18T05:46:36.787211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_res = tf.keras.utils.to_categorical(y_res)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:36.790708Z","iopub.execute_input":"2023-09-18T05:46:36.791079Z","iopub.status.idle":"2023-09-18T05:46:36.796911Z","shell.execute_reply.started":"2023-09-18T05:46:36.791044Z","shell.execute_reply":"2023-09-18T05:46:36.795826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling\nModelling step, I will use Simple NN as the training model","metadata":{}},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-09-18T05:46:36.798165Z","iopub.execute_input":"2023-09-18T05:46:36.798501Z","iopub.status.idle":"2023-09-18T05:46:42.095859Z","shell.execute_reply.started":"2023-09-18T05:46:36.798470Z","shell.execute_reply":"2023-09-18T05:46:42.094468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.Sequential()\n    model.add(tf.keras.layers.Dense(units = 1024, activation = 'relu', input_dim = X_res.shape[1]))\n    model.add(tf.keras.layers.Dense(units = 512, activation = 'relu'))\n    model.add(tf.keras.layers.Dense(units = 256, activation = 'relu'))\n    model.add(tf.keras.layers.Dense(units = y_res.shape[1], activation = 'softmax'))\n\nmodel.summary()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-09-18T05:46:42.097328Z","iopub.execute_input":"2023-09-18T05:46:42.097641Z","iopub.status.idle":"2023-09-18T05:46:43.696099Z","shell.execute_reply.started":"2023-09-18T05:46:42.097605Z","shell.execute_reply":"2023-09-18T05:46:43.694848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001),\n              metrics = ['accuracy'], loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-09-18T05:46:43.697492Z","iopub.execute_input":"2023-09-18T05:46:43.697829Z","iopub.status.idle":"2023-09-18T05:46:43.797925Z","shell.execute_reply.started":"2023-09-18T05:46:43.697801Z","shell.execute_reply":"2023-09-18T05:46:43.796599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_res, y_res, batch_size = 10, \n                    epochs = 10, validation_split = 0.2, verbose=1,\n                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor = 'accuracy', min_delta = 0.0001)])","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:46:43.799220Z","iopub.execute_input":"2023-09-18T05:46:43.799554Z","iopub.status.idle":"2023-09-18T05:47:19.396519Z","shell.execute_reply.started":"2023-09-18T05:46:43.799525Z","shell.execute_reply":"2023-09-18T05:47:19.395209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_loss, valid_acc = model.evaluate(X_valid, y_valid)\n\nprint('Valid Loss:', valid_loss)\nprint('Valid Accuracy:', valid_acc)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:47:19.398096Z","iopub.execute_input":"2023-09-18T05:47:19.398474Z","iopub.status.idle":"2023-09-18T05:47:20.695307Z","shell.execute_reply.started":"2023-09-18T05:47:19.398440Z","shell.execute_reply":"2023-09-18T05:47:20.694125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create figure with secondary y-axis\nfig_model = make_subplots(specs=[[{'secondary_y': True}]])\n\n# Add traces\nfig_model.add_trace(\n    go.Scatter( y=history.history['val_loss'], name='val_loss'),\n    secondary_y=False,\n)\n\nfig_model.add_trace(\n    go.Scatter( y=history.history['loss'], name='loss'),\n    secondary_y=False,\n)\n\nfig_model.add_trace(\n    go.Scatter( y=history.history['val_accuracy'], name='val accuracy'),\n    secondary_y=True,\n)\n\nfig_model.add_trace(\n    go.Scatter( y=history.history['accuracy'], name='val accuracy'),\n    secondary_y=True,\n)\n\n# Add figure title\nfig_model.update_layout(\n    title_text='Loss/Accuracy of SimpleNN Model'\n)\n\n# Set x-axis title\nfig_model.update_xaxes(title_text='Epoch')\n\n# Set y-axes titles\nfig_model.update_yaxes(title_text='<b>primary</b> Loss', secondary_y=False)\nfig_model.update_yaxes(title_text='<b>secondary</b> Accuracy', secondary_y=True)\n\nfig_model.show(renderer='svg')","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:47:20.696552Z","iopub.execute_input":"2023-09-18T05:47:20.696887Z","iopub.status.idle":"2023-09-18T05:47:20.880398Z","shell.execute_reply.started":"2023-09-18T05:47:20.696856Z","shell.execute_reply":"2023-09-18T05:47:20.879320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save model as format `tf`\nmodel.save('model/rnn')","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:47:20.881556Z","iopub.execute_input":"2023-09-18T05:47:20.881888Z","iopub.status.idle":"2023-09-18T05:47:22.191166Z","shell.execute_reply.started":"2023-09-18T05:47:20.881858Z","shell.execute_reply":"2023-09-18T05:47:22.189817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate\nNow, evaluation the model with predict `Test data` and compare the predict with real label and show the result with `classification_report`","metadata":{}},{"cell_type":"code","source":"y_pred = model.predict(X_test)\n\nprint(classification_report(y_test.argmax(1), y_pred.argmax(1), target_names=['not spam','spam']))","metadata":{"execution":{"iopub.status.busy":"2023-09-18T05:47:22.193187Z","iopub.execute_input":"2023-09-18T05:47:22.193521Z","iopub.status.idle":"2023-09-18T05:47:23.959740Z","shell.execute_reply.started":"2023-09-18T05:47:22.193491Z","shell.execute_reply":"2023-09-18T05:47:23.958503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the report, in each class on precision, the model can predict each class correctly by 98%. And on recall, the success rate of the model can find back the information by 92%.","metadata":{}},{"cell_type":"markdown","source":"# Conclusion\nIn this notebook create spam email detection with SMOTE resampling and Simple NN Model, the model has predict capability on validation training by 98% and testing by 98%. With SMOTE, the model can predict better for each class, and result of model are not indicated overfitting or underfitting.\n<br>\nOverall, the model can predict as well :)\n<br>\n<br>\n<b>Thank you for reading my notebook!</b>","metadata":{}},{"cell_type":"markdown","source":"# References\n1. Why 70/30 or 80/20 Relation Between Training and Testing Sets: A Pedagogical Explanation <i>(https://www.cs.utep.edu/vladik/2018/tr18-09.pdf)</i>\n2. How to split data into three sets (train, validation, and test) And why? <i>(https://medium.com/towards-data-science/how-to-split-data-into-three-sets-train-validation-and-test-and-why-e50d22d3e54c)</i>\n3. Effective Class-Imbalance Learning Based on SMOTE and Convolutional Neural Networks <i>(https://www.mdpi.com/2076-3417/13/6/4006)</i>","metadata":{}}]}